{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-17T23:31:55.461393Z",
     "start_time": "2025-04-17T23:31:46.158818Z"
    }
   },
   "source": [
    "# Import des bibliothèques nécessaires\n",
    "from datasets import load_dataset\n",
    "from datasets import concatenate_datasets\n",
    "from transformers import AutoModel\n",
    "import torch\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Authentification à Hugging Face (nécessaire pour accéder aux datasets)\n",
    "# Vous devrez avoir généré un token sur https://huggingface.co/settings/tokens\n",
    "# et exécuté `huggingface-cli login` en ligne de commande avant de lancer ce script\n",
    "# ou utiliser la méthode ci-dessous avec votre token\n",
    "\n",
    "# Décommentez et ajoutez votre token si vous n'avez pas fait login via CLI\n",
    "# login(token=\"votre_token_huggingface\")\n",
    "\n",
    "def load_and_prepare_datasets():\n",
    "    \"\"\"\n",
    "    Charge les datasets ALOHA (transfer et insertion), ajoute un encodage de tâche,\n",
    "    et concatène les données en un vecteur d'entrée de 101 dimensions.\n",
    "    \"\"\"\n",
    "    print(\"Chargement des datasets...\")\n",
    "    ds_transfer = load_dataset(\"lerobot/aloha_sim_transfer_cube_human\")\n",
    "    ds_insertion = load_dataset(\"lerobot/aloha_sim_insertion_human\")\n",
    "\n",
    "    def process_example(example, task_tag):\n",
    "        \"\"\"\n",
    "        Prépare un vecteur d'entrée de 101 dimensions pour chaque exemple.\n",
    "        \"\"\"\n",
    "        obs = np.array(example[\"observation.state\"], dtype=np.float32)\n",
    "        act = np.array(example[\"action\"], dtype=np.float32)\n",
    "        \n",
    "        # One-hot encoding simple pour 2 classes : [1, 0] pour transfer, [0, 1] pour insertion\n",
    "        task_one_hot = np.array([1, 0], dtype=np.float32) if task_tag == \"transfer\" else np.array([0, 1], dtype=np.float32)\n",
    "        \n",
    "        # Concaténation des features\n",
    "        combined = np.concatenate([obs, act, task_one_hot])\n",
    "        \n",
    "        # Padding si nécessaire (ici on pad jusqu'à 101 dim)\n",
    "        padding_length = 101 - combined.shape[0]\n",
    "        if padding_length > 0:\n",
    "            combined = np.concatenate([combined, np.zeros(padding_length, dtype=np.float32)])\n",
    "        \n",
    "        # Ajoute un champ \"input_vector\" pour l'entraînement\n",
    "        example[\"input_vector\"] = combined\n",
    "        return example\n",
    "\n",
    "    def preprocess_dataset(dataset, task_tag):\n",
    "        return dataset.map(lambda ex: process_example(ex, task_tag))\n",
    "\n",
    "    print(\"Prétraitement des datasets...\")\n",
    "    processed_transfer = preprocess_dataset(ds_transfer[\"train\"], \"transfer\")\n",
    "    processed_insertion = preprocess_dataset(ds_insertion[\"train\"], \"insertion\")\n",
    "\n",
    "    print(\"Concaténation des datasets...\")\n",
    "    combined_dataset = concatenate_datasets([processed_transfer, processed_insertion])\n",
    "\n",
    "    print(f\"Nombre total d'échantillons : {len(combined_dataset)}\")\n",
    "    print(\"Exemple d'input_vector (shape) :\", torch.tensor(combined_dataset[0][\"input_vector\"]).shape)\n",
    "    \n",
    "    return combined_dataset\n",
    "\n",
    "# Exécution de la fonction de préparation des datasets\n",
    "if __name__ == \"__main__\":\n",
    "    combined_dataset = load_and_prepare_datasets()\n",
    "    \n",
    "    # Exemple d'accès aux données du dataset combiné\n",
    "    if \"train\" in combined_dataset:\n",
    "        train_split = combined_dataset[\"train\"]\n",
    "        \n",
    "        # Comptage des échantillons par type de tâche\n",
    "        task_counts = train_split.to_pandas()[\"task_tag\"].value_counts()\n",
    "        print(\"\\nRépartition des tâches dans le split 'train':\")\n",
    "        print(task_counts)\n",
    "        \n",
    "        # Échantillon aléatoire pour vérification\n",
    "        print(\"\\nExemple d'échantillon du dataset combiné:\")\n",
    "        random_sample = train_split[np.random.randint(0, len(train_split))]\n",
    "        print(f\"Tâche: {random_sample['task_tag']}\")\n",
    "        for key in random_sample:\n",
    "            if key != \"task_tag\" and isinstance(random_sample[key], (int, float, str, bool)):\n",
    "                print(f\"{key}: {random_sample[key]}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des datasets...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a2a5707fdf3413fa24fc54b88eb5f64"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aec63e1175de4f3b8400d00288a03e8e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f1d7c090795942aca5d5fa009b427587"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5926831968484026adbaf3b5fe2abd92"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prétraitement des datasets...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae978902966b4f398d0106936dc5bef3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea4b03fcc433452386c0a41285c4b76f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concaténation des datasets...\n",
      "Nombre total d'échantillons : 45000\n",
      "Exemple d'input_vector (shape) : torch.Size([101])\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T16:17:14.589491Z",
     "start_time": "2025-04-18T16:17:14.583884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#New dataset creation function\n",
    "from datasets import load_dataset, concatenate_datasets, DatasetDict\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def load_and_prepare_datasets():\n",
    "    \"\"\"\n",
    "    Charge les datasets ALOHA (transfer et insertion), ajoute un encodage de tâche,\n",
    "    et concatène les données en un vecteur d'entrée de 101 dimensions.\n",
    "    \"\"\"\n",
    "    print(\"Chargement des datasets...\")\n",
    "    ds_transfer = load_dataset(\"lerobot/aloha_sim_transfer_cube_human\")\n",
    "    ds_insertion = load_dataset(\"lerobot/aloha_sim_insertion_human\")\n",
    "\n",
    "    def process_example(example, task_tag):\n",
    "        \"\"\"\n",
    "        Prépare un vecteur d'entrée de 101 dimensions pour chaque exemple.\n",
    "        \"\"\"\n",
    "        obs = np.array(example[\"observation.state\"], dtype=np.float32)\n",
    "        act = np.array(example[\"action\"], dtype=np.float32)\n",
    "        \n",
    "        # One-hot encoding simple pour 2 classes : [1, 0] pour transfer, [0, 1] pour insertion\n",
    "        task_one_hot = np.array([1, 0], dtype=np.float32) if task_tag == \"transfer\" else np.array([0, 1], dtype=np.float32)\n",
    "        \n",
    "        # Concaténation des features\n",
    "        combined = np.concatenate([obs, act, task_one_hot])\n",
    "        \n",
    "        # Padding si nécessaire (ici on pad jusqu'à 101 dim)\n",
    "        padding_length = 101 - combined.shape[0]\n",
    "        if padding_length > 0:\n",
    "            combined = np.concatenate([combined, np.zeros(padding_length, dtype=np.float32)])\n",
    "        \n",
    "        # Ajoute un champ \"input_vector\" pour l'entraînement\n",
    "        example[\"input_vector\"] = combined\n",
    "        return example\n",
    "\n",
    "    def preprocess_dataset(dataset, task_tag):\n",
    "        return dataset.map(lambda ex: process_example(ex, task_tag))\n",
    "\n",
    "    print(\"Prétraitement des datasets...\")\n",
    "    processed_transfer = preprocess_dataset(ds_transfer[\"train\"], \"transfer\")\n",
    "    processed_insertion = preprocess_dataset(ds_insertion[\"train\"], \"insertion\")\n",
    "\n",
    "    print(\"Concaténation des datasets...\")\n",
    "    combined_dataset = concatenate_datasets([processed_transfer, processed_insertion])\n",
    "\n",
    "    print(f\"Nombre total d'échantillons : {len(combined_dataset)}\")\n",
    "    print(\"Exemple d'input_vector (shape) :\", torch.tensor(combined_dataset[0][\"input_vector\"]).shape)\n",
    "    \n",
    "    return combined_dataset"
   ],
   "id": "ea40603330cb369b",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T16:17:14.997115Z",
     "start_time": "2025-04-18T16:17:14.994282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ActModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        obs_dim=101,       # tu devras adapter ces dimensions selon ton cas\n",
    "        action_dim=7,\n",
    "        hidden_dim=512,\n",
    "        n_layers=4,\n",
    "        dropout=0.1,\n",
    "        use_layer_norm=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.obs_dim = obs_dim\n",
    "        self.action_dim = action_dim\n",
    "\n",
    "        self.input_layer = nn.Linear(obs_dim, hidden_dim)\n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=hidden_dim,\n",
    "                nhead=8,\n",
    "                dim_feedforward=hidden_dim * 4,\n",
    "                dropout=dropout,\n",
    "                batch_first=True,\n",
    "                norm_first=use_layer_norm,\n",
    "            ) for _ in range(n_layers)\n",
    "        ])\n",
    "        self.output_layer = nn.Linear(hidden_dim, action_dim)\n",
    "\n",
    "    def forward(self, obs):\n",
    "        x = self.input_layer(obs)\n",
    "        for layer in self.transformer_layers:\n",
    "            x = layer(x)\n",
    "        return self.output_layer(x)"
   ],
   "id": "35e5e2707e336625",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T16:17:15.365822Z",
     "start_time": "2025-04-18T16:17:15.363215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from safetensors.torch import load_file\n",
    "\n",
    "def load_act_model(model_path):\n",
    "    model = ActModel(\n",
    "        obs_dim=101,       # adapte ces valeurs si nécessaire\n",
    "        action_dim=7,\n",
    "        hidden_dim=512,\n",
    "        n_layers=4,\n",
    "        dropout=0.1,\n",
    "        use_layer_norm=True\n",
    "    )\n",
    "\n",
    "    state_dict = load_file(model_path)\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    return model"
   ],
   "id": "3b0b53225b7846f8",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T16:17:15.799203Z",
     "start_time": "2025-04-18T16:17:15.681024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transfer_model = load_act_model(\"/Users/louloute/PycharmProjects/INF8225_projet/Models/transfer/model.safetensors\")\n",
    "insertion_model = load_act_model(\"/Users/louloute/PycharmProjects/INF8225_projet/Models/insertion/model.safetensors\")\n",
    "print(transfer_model)"
   ],
   "id": "895e4ce0d96d2681",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ActModel(\n",
      "  (input_layer): Linear(in_features=101, out_features=512, bias=True)\n",
      "  (transformer_layers): ModuleList(\n",
      "    (0-3): 4 x TransformerEncoderLayer(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "      (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (output_layer): Linear(in_features=512, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T16:29:05.552088Z",
     "start_time": "2025-04-18T16:29:05.545043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class UnifiedALOHAModel(nn.Module):\n",
    "    def __init__(self, transfer_model, insertion_model, output_dim=768):\n",
    "        super(UnifiedALOHAModel, self).__init__()\n",
    "\n",
    "        self.transfer_model = transfer_model\n",
    "        self.insertion_model = insertion_model\n",
    "\n",
    "        for param in self.transfer_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in self.insertion_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # On suppose que les modèles retournent un vecteur de même taille que la dernière couche\n",
    "        # Pour éviter les erreurs, on utilise une passe fictive pour obtenir la dimension de sortie réelle\n",
    "        # Passe fictive pour obtenir les dimensions de sortie\n",
    "        dummy_input = torch.randn(1, 101)  # Supposons que les features d'entrée font 128 dimensions\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            transfer_out = self.transfer_model(dummy_input)\n",
    "            insertion_out = self.insertion_model(dummy_input)\n",
    "        \n",
    "        # Si la sortie est un tuple (ex: (out, hidden)), on garde out\n",
    "        if isinstance(transfer_out, tuple):\n",
    "            transfer_out = transfer_out[0]\n",
    "        if isinstance(insertion_out, tuple):\n",
    "            insertion_out = insertion_out[0]\n",
    "        \n",
    "        transfer_output_size = transfer_out.shape[1]\n",
    "        insertion_output_size = insertion_out.shape[1]\n",
    "        with torch.no_grad():\n",
    "            transfer_out = transfer_model(dummy_input)\n",
    "            insertion_out = insertion_model(dummy_input)\n",
    "\n",
    "        transfer_dim = transfer_out.shape[1]\n",
    "        insertion_dim = insertion_out.shape[1]\n",
    "\n",
    "        self.task_embedding = nn.Embedding(2, 64)  # Embedding pour la tâche (0 ou 1)\n",
    "\n",
    "        self.fusion_layer = nn.Sequential(\n",
    "            nn.Linear(transfer_dim + insertion_dim + 64, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Linear(256, output_dim)\n",
    "        self.layer_norm = nn.LayerNorm(output_dim)\n",
    "\n",
    "    def forward(self, features, task_id=None):  \n",
    "        \"\"\"\n",
    "        Args:\n",
    "            features: (batch_size, input_dim)\n",
    "            task_id: (batch_size, 1) ou (batch_size,) — type long ou None\n",
    "    \n",
    "        Returns:\n",
    "            (batch_size, output_dim)\n",
    "        \"\"\"\n",
    "        batch_size = features.size(0)\n",
    "        \n",
    "        if task_id is not None:\n",
    "            task_emb = self.task_embedding(task_id.view(-1))  # (batch_size, 64)\n",
    "        else:\n",
    "            # Si task_id n'est pas fourni, on utilise un vecteur nul ou moyen\n",
    "            task_emb = torch.zeros(batch_size, self.task_embedding.embedding_dim, device=features.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            transfer_out = self.transfer_model(features)  # (batch_size, transfer_dim)\n",
    "            insertion_out = self.insertion_model(features)  # (batch_size, insertion_dim)\n",
    "        \n",
    "        if isinstance(transfer_out, tuple):\n",
    "            transfer_out = transfer_out[0]\n",
    "        if isinstance(insertion_out, tuple):\n",
    "            insertion_out = insertion_out[0]\n",
    "        \n",
    "        combined = torch.cat([transfer_out, insertion_out, task_emb], dim=1)  # (batch_size, total_dim)\n",
    "        fused = self.fusion_layer(combined)\n",
    "        output = self.output_layer(fused)\n",
    "        output = self.layer_norm(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "        "
   ],
   "id": "8a6c4093821b54e1",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T16:36:01.226965Z",
     "start_time": "2025-04-18T16:36:01.219282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import des bibliothèques nécessaires\n",
    "from transformers import AutoModel, AutoConfig, PreTrainedModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import wandb  # Pour le suivi des expériences (optionnel)\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import ALOHADataset\n",
    "\n",
    "# Fonction pour l'entraînement du modèle unifié\n",
    "def train_unified_model(unified_model, train_dataloader, val_dataloader, \n",
    "                        num_epochs=10, learning_rate=1e-4, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Entraîne le modèle unifié.\n",
    "    \n",
    "    Args:\n",
    "        unified_model: Le modèle unifié\n",
    "        train_dataloader: DataLoader pour les données d'entraînement\n",
    "        val_dataloader: DataLoader pour les données de validation\n",
    "        num_epochs: Nombre d'époques d'entraînement\n",
    "        learning_rate: Taux d'apprentissage\n",
    "        device: Appareil sur lequel effectuer l'entraînement ('cuda' ou 'cpu')\n",
    "    \n",
    "    Returns:\n",
    "        Le modèle entraîné et les historiques de perte\n",
    "    \"\"\"\n",
    "    unified_model = unified_model.to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()  # À adapter si classification\n",
    "    optimizer = torch.optim.Adam(unified_model.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=2, verbose=True\n",
    "    )\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        unified_model.train()\n",
    "        epoch_train_loss = 0.0\n",
    "        train_batches = 0\n",
    "\n",
    "        for batch in tqdm(train_dataloader, desc=f\"Époque {epoch+1}/{num_epochs} (entraînement)\"):\n",
    "            features = batch[\"features\"].float().to(device)\n",
    "            labels = batch[\"labels\"].float().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = unified_model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # Optionnel : clip grad pour éviter les explosions de gradient\n",
    "            torch.nn.utils.clip_grad_norm_(unified_model.parameters(), max_norm=1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "            epoch_train_loss += loss.item()\n",
    "            train_batches += 1\n",
    "\n",
    "        epoch_train_loss /= train_batches\n",
    "        train_losses.append(epoch_train_loss)\n",
    "\n",
    "        unified_model.eval()\n",
    "        epoch_val_loss = 0.0\n",
    "        val_batches = 0\n",
    "        print(\"features shape:\", features.shape)  # debug\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_dataloader, desc=f\"Époque {epoch+1}/{num_epochs} (validation)\"):\n",
    "                features = batch[\"features\"].float().to(device)\n",
    "                labels = batch[\"labels\"].float().to(device)\n",
    "\n",
    "                outputs = unified_model(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                epoch_val_loss += loss.item()\n",
    "                val_batches += 1\n",
    "\n",
    "        epoch_val_loss /= val_batches\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        scheduler.step(epoch_val_loss)\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Époque {epoch+1}/{num_epochs} - \"\n",
    "              f\"LR: {current_lr:.2e} | \"\n",
    "              f\"Train Loss: {epoch_train_loss:.6f} | \"\n",
    "              f\"Val Loss: {epoch_val_loss:.6f}\")\n",
    "\n",
    "    return unified_model, train_losses, val_losses\n",
    "\n"
   ],
   "id": "58fb220133d63b69",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T16:36:04.383570Z",
     "start_time": "2025-04-18T16:36:04.379228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fonction pour fine-tuner le modèle unifié (dégeler certaines couches)\n",
    "def fine_tune_unified_model(unified_model, train_dataloader, val_dataloader, \n",
    "                           num_epochs=5, learning_rate=5e-5, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Fine-tune le modèle unifié en dégelant certaines couches des modèles pré-entraînés.\n",
    "    \n",
    "    Args:\n",
    "        unified_model: Le modèle unifié\n",
    "        train_dataloader: DataLoader pour les données d'entraînement\n",
    "        val_dataloader: DataLoader pour les données de validation\n",
    "        num_epochs: Nombre d'époques d'entraînement\n",
    "        learning_rate: Taux d'apprentissage\n",
    "        device: Appareil sur lequel effectuer l'entraînement ('cuda' ou 'cpu')\n",
    "    \n",
    "    Returns:\n",
    "        Le modèle fine-tuné et les historiques de perte\n",
    "    \"\"\"\n",
    "    # Dégeler les dernières couches des modèles pré-entraînés\n",
    "    for name, param in unified_model.transfer_model.named_parameters():\n",
    "        if \"layer\" in name and any(f\"layer.{i}\" in name for i in [10, 11]):  # Dégeler les 2 dernières couches\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    for name, param in unified_model.insertion_model.named_parameters():\n",
    "        if \"layer\" in name and any(f\"layer.{i}\" in name for i in [10, 11]):  # Dégeler les 2 dernières couches\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    # Entraîner le modèle avec les couches dégelées\n",
    "    return train_unified_model(unified_model, train_dataloader, val_dataloader, \n",
    "                              num_epochs=num_epochs, learning_rate=learning_rate, device=device)"
   ],
   "id": "257ee1e75587e26a",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T16:36:06.866708Z",
     "start_time": "2025-04-18T16:36:04.925750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Dataset PyTorch à partir du champ input_vector\n",
    "class ALOHADataset(Dataset):\n",
    "    def __init__(self, hf_dataset):\n",
    "        self.dataset = hf_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_vector = torch.tensor(self.dataset[idx][\"input_vector\"], dtype=torch.float32)\n",
    "        label = torch.tensor(self.dataset[idx][\"action\"], dtype=torch.float32)  # ou un autre champ si tu préfères\n",
    "        return {\n",
    "            \"features\": input_vector,\n",
    "            \"labels\": label\n",
    "        }\n",
    "\n",
    "# Fonction principale\n",
    "def main():\n",
    "    # Charger le dataset combiné avec les vecteurs à 101 dimensions\n",
    "    combined_dataset = load_and_prepare_datasets()\n",
    "\n",
    "    # Créer l'objet Dataset PyTorch\n",
    "    full_dataset = ALOHADataset(combined_dataset)\n",
    "    \n",
    "    # Split en train/val\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "    # 🔍 DEBUG : Afficher la forme des features d’un exemple\n",
    "    sample = train_dataset[0]\n",
    "    print(f\"Shape des features du premier exemple: {sample['features'].shape}\")\n",
    "\n",
    "    # Créer les dataloaders\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "    # Charger les modèles pré-entraînés\n",
    "    transfer_model = load_act_model(\"/Users/louloute/PycharmProjects/INF8225_projet/Models/transfer/model.safetensors\")\n",
    "    insertion_model = load_act_model(\"/Users/louloute/PycharmProjects/INF8225_projet/Models/insertion/model.safetensors\")\n",
    "\n",
    "    # Créer le modèle unifié\n",
    "    unified_model = UnifiedALOHAModel(transfer_model, insertion_model)\n",
    "\n",
    "    # Déterminer l'appareil à utiliser\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Utilisation de l'appareil: {device}\")\n",
    "\n",
    "    # Entraîner le modèle unifié\n",
    "    print(\"\\nEntraînement du modèle unifié...\")\n",
    "    unified_model, train_losses, val_losses = train_unified_model(\n",
    "        unified_model, train_dataloader, val_dataloader, \n",
    "        num_epochs=10, learning_rate=1e-4, device=device\n",
    "    )\n",
    "\n",
    "    # Fine-tuner le modèle unifié\n",
    "    print(\"\\nFine-tuning du modèle unifié...\")\n",
    "    unified_model, ft_train_losses, ft_val_losses = fine_tune_unified_model(\n",
    "        unified_model, train_dataloader, val_dataloader, \n",
    "        num_epochs=5, learning_rate=5e-5, device=device\n",
    "    )\n",
    "\n",
    "    # Tracer les courbes de perte\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.title('Pertes pendant l\\'entraînement initial')\n",
    "    plt.xlabel('Époque')\n",
    "    plt.ylabel('Perte')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(ft_train_losses, label='Train')\n",
    "    plt.plot(ft_val_losses, label='Validation')\n",
    "    plt.title('Pertes pendant le fine-tuning')\n",
    "    plt.xlabel('Époque')\n",
    "    plt.ylabel('Perte')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_losses.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Sauvegarde\n",
    "    model_save_path = \"unified_aloha_model\"\n",
    "    os.makedirs(model_save_path, exist_ok=True)\n",
    "    torch.save(unified_model.state_dict(), os.path.join(model_save_path, \"unified_model.pt\"))\n",
    "    print(f\"Modèle unifié sauvegardé dans {model_save_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "97555aec1a88b835",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des datasets...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e98b4258c40a49c39b7ee5b235f06d97"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8a02d2afc704eaf9dafd289c0170beb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "558c6d6d26c64da99b82a0cfdc12bb9b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2010ee253724acebd1dd73ec24fdb9f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prétraitement des datasets...\n",
      "Concaténation des datasets...\n",
      "Nombre total d'échantillons : 45000\n",
      "Exemple d'input_vector (shape) : torch.Size([101])\n",
      "Shape des features du premier exemple: torch.Size([101])\n",
      "Utilisation de l'appareil: cpu\n",
      "\n",
      "Entraînement du modèle unifié...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 1/10 (entraînement):   0%|          | 0/1125 [00:00<?, ?it/s]/Users/louloute/miniconda3/lib/python3.12/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([32, 14])) that is different to the input size (torch.Size([32, 768])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Époque 1/10 (entraînement):   0%|          | 0/1125 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (768) must match the size of tensor b (14) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[98], line 98\u001B[0m\n\u001B[1;32m     95\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModèle unifié sauvegardé dans \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_save_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     97\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m---> 98\u001B[0m     main()\n",
      "Cell \u001B[0;32mIn[98], line 56\u001B[0m, in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;66;03m# Entraîner le modèle unifié\u001B[39;00m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mEntraînement du modèle unifié...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 56\u001B[0m unified_model, train_losses, val_losses \u001B[38;5;241m=\u001B[39m train_unified_model(\n\u001B[1;32m     57\u001B[0m     unified_model, train_dataloader, val_dataloader, \n\u001B[1;32m     58\u001B[0m     num_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-4\u001B[39m, device\u001B[38;5;241m=\u001B[39mdevice\n\u001B[1;32m     59\u001B[0m )\n\u001B[1;32m     61\u001B[0m \u001B[38;5;66;03m# Fine-tuner le modèle unifié\u001B[39;00m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mFine-tuning du modèle unifié...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[96], line 54\u001B[0m, in \u001B[0;36mtrain_unified_model\u001B[0;34m(unified_model, train_dataloader, val_dataloader, num_epochs, learning_rate, device)\u001B[0m\n\u001B[1;32m     52\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     53\u001B[0m outputs \u001B[38;5;241m=\u001B[39m unified_model(features)\n\u001B[0;32m---> 54\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, labels)\n\u001B[1;32m     55\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# Optionnel : clip grad pour éviter les explosions de gradient\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/loss.py:608\u001B[0m, in \u001B[0;36mMSELoss.forward\u001B[0;34m(self, input, target)\u001B[0m\n\u001B[1;32m    607\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 608\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mmse_loss(\u001B[38;5;28minput\u001B[39m, target, reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreduction)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/functional.py:3791\u001B[0m, in \u001B[0;36mmse_loss\u001B[0;34m(input, target, size_average, reduce, reduction)\u001B[0m\n\u001B[1;32m   3788\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3789\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[0;32m-> 3791\u001B[0m expanded_input, expanded_target \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mbroadcast_tensors(\u001B[38;5;28minput\u001B[39m, target)\n\u001B[1;32m   3792\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_nn\u001B[38;5;241m.\u001B[39mmse_loss(\n\u001B[1;32m   3793\u001B[0m     expanded_input, expanded_target, _Reduction\u001B[38;5;241m.\u001B[39mget_enum(reduction)\n\u001B[1;32m   3794\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/torch/functional.py:76\u001B[0m, in \u001B[0;36mbroadcast_tensors\u001B[0;34m(*tensors)\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function(tensors):\n\u001B[1;32m     75\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(broadcast_tensors, tensors, \u001B[38;5;241m*\u001B[39mtensors)\n\u001B[0;32m---> 76\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _VF\u001B[38;5;241m.\u001B[39mbroadcast_tensors(tensors)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: The size of tensor a (768) must match the size of tensor b (14) at non-singleton dimension 1"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T16:33:32.639136Z",
     "start_time": "2025-04-18T16:33:26.718929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fonction principale\n",
    "def main():\n",
    "    # Charger le dataset combiné (à partir du script précédent)\n",
    "    combined_dataset = load_and_prepare_datasets()\n",
    "    \n",
    "    # Créer les datasets PyTorch\n",
    "    if \"train\" in combined_dataset and \"validation\" in combined_dataset:\n",
    "        train_dataset = ALOHADataset(combined_dataset[\"train\"])\n",
    "        val_dataset = ALOHADataset(combined_dataset[\"validation\"])\n",
    "    else:\n",
    "        # Si pas de split validation, créer un à partir du train\n",
    "        full_dataset = ALOHADataset(combined_dataset)\n",
    "        train_size = int(0.8 * len(full_dataset))\n",
    "        val_size = len(full_dataset) - train_size\n",
    "        train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "    # 🔍 DEBUG : Afficher la forme des features d’un exemple\n",
    "    sample = train_dataset[0]\n",
    "    if isinstance(sample, dict) and \"features\" in sample:\n",
    "        print(f\"Shape des features du premier exemple: {sample['features'].shape}\")\n",
    "    else:\n",
    "        print(\"⚠️ Impossible de trouver la clé 'features' dans un exemple.\")\n",
    "    # Créer les dataloaders\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "    \n",
    "    # Charger les modèles pré-entraînés\n",
    "    transfer_model = load_act_model(\"/Users/louloute/PycharmProjects/INF8225_projet/Models/transfer/model.safetensors\")\n",
    "    insertion_model = load_act_model(\"/Users/louloute/PycharmProjects/INF8225_projet/Models/insertion/model.safetensors\")\n",
    "    \n",
    "    # Créer le modèle unifié\n",
    "    unified_model = UnifiedALOHAModel(transfer_model, insertion_model)\n",
    "    \n",
    "    # Déterminer l'appareil à utiliser (GPU ou CPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Utilisation de l'appareil: {device}\")\n",
    "    \n",
    "    # Entraîner le modèle unifié\n",
    "    print(\"\\nEntraînement du modèle unifié...\")\n",
    "    unified_model, train_losses, val_losses = train_unified_model(\n",
    "        unified_model, train_dataloader, val_dataloader, \n",
    "        num_epochs=10, learning_rate=1e-4, device=device\n",
    "    )\n",
    "    \n",
    "    # Fine-tuner le modèle unifié\n",
    "    print(\"\\nFine-tuning du modèle unifié...\")\n",
    "    unified_model, ft_train_losses, ft_val_losses = fine_tune_unified_model(\n",
    "        unified_model, train_dataloader, val_dataloader, \n",
    "        num_epochs=5, learning_rate=5e-5, device=device\n",
    "    )\n",
    "    \n",
    "    # Tracer les courbes de perte\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Courbes de perte pour l'entraînement initial\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.title('Pertes pendant l\\'entraînement initial')\n",
    "    plt.xlabel('Époque')\n",
    "    plt.ylabel('Perte')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Courbes de perte pour le fine-tuning\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(ft_train_losses, label='Train')\n",
    "    plt.plot(ft_val_losses, label='Validation')\n",
    "    plt.title('Pertes pendant le fine-tuning')\n",
    "    plt.xlabel('Époque')\n",
    "    plt.ylabel('Perte')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_losses.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Sauvegarder le modèle unifié\n",
    "    model_save_path = \"unified_aloha_model\"\n",
    "    os.makedirs(model_save_path, exist_ok=True)\n",
    "    torch.save(unified_model.state_dict(), os.path.join(model_save_path, \"unified_model.pt\"))\n",
    "    print(f\"Modèle unifié sauvegardé dans {model_save_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "140029e554bde938",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des datasets...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ca2f8b9cbad4e9abf84684605e17f08"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b0a2c2ecf1094bc9b3689c5abee6da72"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd27210e55644b3da1864c24187eb810"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "71738554e1af44c5ba54fd1b4bff45e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prétraitement des datasets...\n",
      "Concaténation des datasets...\n",
      "Nombre total d'échantillons : 45000\n",
      "Exemple d'input_vector (shape) : torch.Size([101])\n",
      "Shape des features du premier exemple: torch.Size([101])\n",
      "Utilisation de l'appareil: cpu\n",
      "\n",
      "Entraînement du modèle unifié...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 1/10 (entraînement):   0%|          | 0/1125 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/louloute/miniconda3/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/louloute/miniconda3/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'ALOHADataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Époque 1/10 (entraînement):   0%|          | 0/1125 [00:01<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/louloute/miniconda3/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/louloute/miniconda3/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'ALOHADataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 51938) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1243\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1242\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1243\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_queue\u001B[38;5;241m.\u001B[39mget(timeout\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[1;32m   1244\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/multiprocessing/queues.py:113\u001B[0m, in \u001B[0;36mQueue.get\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m    112\u001B[0m timeout \u001B[38;5;241m=\u001B[39m deadline \u001B[38;5;241m-\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n\u001B[0;32m--> 113\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_poll(timeout):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Empty\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/multiprocessing/connection.py:257\u001B[0m, in \u001B[0;36m_ConnectionBase.poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_readable()\n\u001B[0;32m--> 257\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_poll(timeout)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/multiprocessing/connection.py:440\u001B[0m, in \u001B[0;36mConnection._poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    439\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_poll\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout):\n\u001B[0;32m--> 440\u001B[0m     r \u001B[38;5;241m=\u001B[39m wait([\u001B[38;5;28mself\u001B[39m], timeout)\n\u001B[1;32m    441\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mbool\u001B[39m(r)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/multiprocessing/connection.py:1135\u001B[0m, in \u001B[0;36mwait\u001B[0;34m(object_list, timeout)\u001B[0m\n\u001B[1;32m   1134\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m-> 1135\u001B[0m     ready \u001B[38;5;241m=\u001B[39m selector\u001B[38;5;241m.\u001B[39mselect(timeout)\n\u001B[1;32m   1136\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ready:\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/selectors.py:415\u001B[0m, in \u001B[0;36m_PollLikeSelector.select\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    414\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 415\u001B[0m     fd_event_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_selector\u001B[38;5;241m.\u001B[39mpoll(timeout)\n\u001B[1;32m    416\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/_utils/signal_handling.py:73\u001B[0m, in \u001B[0;36m_set_SIGCHLD_handler.<locals>.handler\u001B[0;34m(signum, frame)\u001B[0m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhandler\u001B[39m(signum, frame):\n\u001B[1;32m     71\u001B[0m     \u001B[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001B[39;00m\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;66;03m# Python can still get and update the process status successfully.\u001B[39;00m\n\u001B[0;32m---> 73\u001B[0m     _error_if_any_worker_fails()\n\u001B[1;32m     74\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m previous_handler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mRuntimeError\u001B[0m: DataLoader worker (pid 51938) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[94], line 83\u001B[0m\n\u001B[1;32m     80\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModèle unifié sauvegardé dans \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_save_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     82\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m---> 83\u001B[0m     main()\n",
      "Cell \u001B[0;32mIn[94], line 39\u001B[0m, in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;66;03m# Entraîner le modèle unifié\u001B[39;00m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mEntraînement du modèle unifié...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 39\u001B[0m unified_model, train_losses, val_losses \u001B[38;5;241m=\u001B[39m train_unified_model(\n\u001B[1;32m     40\u001B[0m     unified_model, train_dataloader, val_dataloader, \n\u001B[1;32m     41\u001B[0m     num_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-4\u001B[39m, device\u001B[38;5;241m=\u001B[39mdevice\n\u001B[1;32m     42\u001B[0m )\n\u001B[1;32m     44\u001B[0m \u001B[38;5;66;03m# Fine-tuner le modèle unifié\u001B[39;00m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mFine-tuning du modèle unifié...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[90], line 48\u001B[0m, in \u001B[0;36mtrain_unified_model\u001B[0;34m(unified_model, train_dataloader, val_dataloader, num_epochs, learning_rate, device)\u001B[0m\n\u001B[1;32m     45\u001B[0m epoch_train_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m     46\u001B[0m train_batches \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m---> 48\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m tqdm(train_dataloader, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mÉpoque \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_epochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (entraînement)\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     49\u001B[0m     features \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfeatures\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     50\u001B[0m     labels \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tqdm/std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1181\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1182\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m   1183\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[1;32m   1184\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    699\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 701\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_data()\n\u001B[1;32m    702\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    704\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[1;32m    707\u001B[0m ):\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1448\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1445\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_data(data)\n\u001B[1;32m   1447\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m-> 1448\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_data()\n\u001B[1;32m   1449\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1450\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable:\n\u001B[1;32m   1451\u001B[0m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1412\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._get_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1408\u001B[0m     \u001B[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001B[39;00m\n\u001B[1;32m   1409\u001B[0m     \u001B[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001B[39;00m\n\u001B[1;32m   1410\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1411\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m-> 1412\u001B[0m         success, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_get_data()\n\u001B[1;32m   1413\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[1;32m   1414\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1256\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1254\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(failed_workers) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1255\u001B[0m     pids_str \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mstr\u001B[39m(w\u001B[38;5;241m.\u001B[39mpid) \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m failed_workers)\n\u001B[0;32m-> 1256\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m   1257\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader worker (pid(s) \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpids_str\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) exited unexpectedly\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1258\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m   1259\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e, queue\u001B[38;5;241m.\u001B[39mEmpty):\n\u001B[1;32m   1260\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: DataLoader worker (pid(s) 51938) exited unexpectedly"
     ]
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T23:48:24.719031Z",
     "start_time": "2025-04-14T23:48:24.715837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import des bibliothèques nécessaires\n",
    "from transformers import AutoModel, AutoConfig, PreTrainedModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import wandb  # Pour le suivi des expériences (optionnel)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fonction de chargement des modèles pré-entraînés pour les deux tâches\n",
    "def load_pretrained_models():\n",
    "    \"\"\"\n",
    "    Charge les deux modèles pré-entraînés: un pour le transfert et un pour l'insertion\n",
    "    à partir des chemins locaux.\n",
    "    \"\"\"\n",
    "    print(\"Chargement du modèle pour la tâche de transfert...\")\n",
    "    transfer_model_path = \"/Users/louloute/PycharmProjects/INF8225_projet/Models/transfer/model.safetensors\"\n",
    "    transfer_model = AutoModel.from_pretrained(\n",
    "        os.path.dirname(transfer_model_path),\n",
    "        local_files_only=True\n",
    "    )\n",
    "    \n",
    "    print(\"Chargement du modèle pour la tâche d'insertion...\")\n",
    "    insertion_model_path = \"/Users/louloute/PycharmProjects/INF8225_projet/Models/insertion/model.safetensors\"\n",
    "    insertion_model = AutoModel.from_pretrained(\n",
    "        os.path.dirname(insertion_model_path),\n",
    "        local_files_only=True\n",
    "    )\n",
    "    \n",
    "    # Afficher l'architecture des modèles\n",
    "    print(\"\\nArchitecture du modèle de transfert:\")\n",
    "    print(transfer_model)\n",
    "    \n",
    "    print(\"\\nArchitecture du modèle d'insertion:\")\n",
    "    print(insertion_model)\n",
    "    \n",
    "    # Examiner les paramètres des modèles\n",
    "    transfer_params = sum(p.numel() for p in transfer_model.parameters())\n",
    "    insertion_params = sum(p.numel() for p in insertion_model.parameters())\n",
    "    \n",
    "    print(f\"\\nNombre de paramètres du modèle de transfert: {transfer_params:,}\")\n",
    "    print(f\"Nombre de paramètres du modèle d'insertion: {insertion_params:,}\")\n",
    "    \n",
    "    return transfer_model, insertion_model"
   ],
   "id": "624ffc882932aebe",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5964618e80f3f192"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
