{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-17T15:59:52.122035Z",
     "start_time": "2025-04-17T15:59:39.745949Z"
    }
   },
   "source": [
    "# Import des bibliothèques nécessaires\n",
    "from datasets import load_dataset\n",
    "from datasets import concatenate_datasets\n",
    "from transformers import AutoModel\n",
    "import torch\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Authentification à Hugging Face (nécessaire pour accéder aux datasets)\n",
    "# Vous devrez avoir généré un token sur https://huggingface.co/settings/tokens\n",
    "# et exécuté `huggingface-cli login` en ligne de commande avant de lancer ce script\n",
    "# ou utiliser la méthode ci-dessous avec votre token\n",
    "\n",
    "# Décommentez et ajoutez votre token si vous n'avez pas fait login via CLI\n",
    "# login(token=\"votre_token_huggingface\")\n",
    "\n",
    "def load_and_prepare_datasets():\n",
    "    \"\"\"\n",
    "    Charge les deux datasets d'ALOHA et les concatène en ajoutant des tags\n",
    "    pour distinguer les actions.\n",
    "    \"\"\"\n",
    "    print(\"Chargement du dataset pour la tâche de transfert...\")\n",
    "    ds_transfer = load_dataset(\"lerobot/aloha_sim_transfer_cube_human\")\n",
    "    \n",
    "    print(\"Chargement du dataset pour la tâche d'insertion...\")\n",
    "    ds_insertion = load_dataset(\"lerobot/aloha_sim_insertion_human\")\n",
    "    \n",
    "    # Affichage des informations sur les datasets\n",
    "    print(f\"Dataset transfert: {ds_transfer}\")\n",
    "    print(f\"Dataset insertion: {ds_insertion}\")\n",
    "    \n",
    "    # Récupération des échantillons pour examiner la structure\n",
    "    transfer_example = ds_transfer[\"train\"][0] if \"train\" in ds_transfer else ds_transfer[next(iter(ds_transfer))][0]\n",
    "    insertion_example = ds_insertion[\"train\"][0] if \"train\" in ds_insertion else ds_insertion[next(iter(ds_insertion))][0]\n",
    "    \n",
    "    print(\"\\nExemple d'échantillon de transfert:\")\n",
    "    for key in transfer_example:\n",
    "        if isinstance(transfer_example[key], (int, float, str, bool)):\n",
    "            print(f\"{key}: {transfer_example[key]}\")\n",
    "        else:\n",
    "            print(f\"{key}: Type {type(transfer_example[key])}, Forme {np.array(transfer_example[key]).shape if hasattr(transfer_example[key], '__len__') else 'scalaire'}\")\n",
    "    \n",
    "    print(\"\\nExemple d'échantillon d'insertion:\")\n",
    "    for key in insertion_example:\n",
    "        if isinstance(insertion_example[key], (int, float, str, bool)):\n",
    "            print(f\"{key}: {insertion_example[key]}\")\n",
    "        else:\n",
    "            print(f\"{key}: Type {type(insertion_example[key])}, Forme {np.array(insertion_example[key]).shape if hasattr(insertion_example[key], '__len__') else 'scalaire'}\")\n",
    "    \n",
    "    # Fonction pour ajouter un tag à chaque échantillon\n",
    "    def add_task_tag_to_dataset(dataset, task_tag):\n",
    "        \"\"\"Ajoute un tag de tâche à chaque échantillon du dataset.\"\"\"\n",
    "        def add_tag(example):\n",
    "            example[\"task_tag\"] = task_tag\n",
    "            return example\n",
    "        \n",
    "        # Applique la fonction à chaque split du dataset\n",
    "        tagged_dataset = {}\n",
    "        for split in dataset:\n",
    "            tagged_dataset[split] = dataset[split].map(add_tag)\n",
    "        \n",
    "        return tagged_dataset\n",
    "    \n",
    "    # Ajouter les tags aux datasets\n",
    "    print(\"\\nAjout des tags aux datasets...\")\n",
    "    tagged_transfer = add_task_tag_to_dataset(ds_transfer, \"transfer\")\n",
    "    tagged_insertion = add_task_tag_to_dataset(ds_insertion, \"insertion\")\n",
    "    \n",
    "    # Concaténer les datasets\n",
    "    print(\"Concaténation des datasets...\")\n",
    "    combined_dataset = {}\n",
    "    \n",
    "    # Pour chaque split présent dans au moins l'un des datasets\n",
    "    all_splits = set(tagged_transfer.keys()).union(set(tagged_insertion.keys()))\n",
    "    for split in all_splits:\n",
    "        if split in tagged_transfer and split in tagged_insertion:\n",
    "            # Si le split existe dans les deux datasets, les concaténer\n",
    "            combined_dataset[split] = concatenate_datasets([tagged_transfer[split], tagged_insertion[split]])\n",
    "        elif split in tagged_transfer:\n",
    "            # Si le split n'existe que dans le dataset de transfert\n",
    "            combined_dataset[split] = tagged_transfer[split]\n",
    "        else:\n",
    "            # Si le split n'existe que dans le dataset d'insertion\n",
    "            combined_dataset[split] = tagged_insertion[split]\n",
    "    \n",
    "    # Afficher les informations sur le dataset combiné\n",
    "    print(\"\\nDataset combiné:\")\n",
    "    for split in combined_dataset:\n",
    "        print(f\"{split}: {len(combined_dataset[split])} échantillons\")\n",
    "    \n",
    "    return combined_dataset\n",
    "\n",
    "# Exécution de la fonction de préparation des datasets\n",
    "if __name__ == \"__main__\":\n",
    "    combined_dataset = load_and_prepare_datasets()\n",
    "    \n",
    "    # Exemple d'accès aux données du dataset combiné\n",
    "    if \"train\" in combined_dataset:\n",
    "        train_split = combined_dataset[\"train\"]\n",
    "        \n",
    "        # Comptage des échantillons par type de tâche\n",
    "        task_counts = train_split.to_pandas()[\"task_tag\"].value_counts()\n",
    "        print(\"\\nRépartition des tâches dans le split 'train':\")\n",
    "        print(task_counts)\n",
    "        \n",
    "        # Échantillon aléatoire pour vérification\n",
    "        print(\"\\nExemple d'échantillon du dataset combiné:\")\n",
    "        random_sample = train_split[np.random.randint(0, len(train_split))]\n",
    "        print(f\"Tâche: {random_sample['task_tag']}\")\n",
    "        for key in random_sample:\n",
    "            if key != \"task_tag\" and isinstance(random_sample[key], (int, float, str, bool)):\n",
    "                print(f\"{key}: {random_sample[key]}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du dataset pour la tâche de transfert...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "050d54709a714259a7990016e4cbfa78"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db0f0122c5b644f395c6ed5400c93d67"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du dataset pour la tâche d'insertion...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b9e809166e98455dbe414f8dab4d109f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a30c2055c954460be1a2630911dba48"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset transfert: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['observation.state', 'action', 'episode_index', 'frame_index', 'timestamp', 'next.done', 'index', 'task_index'],\n",
      "        num_rows: 20000\n",
      "    })\n",
      "})\n",
      "Dataset insertion: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['observation.state', 'action', 'episode_index', 'frame_index', 'timestamp', 'next.done', 'index', 'task_index'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "})\n",
      "\n",
      "Exemple d'échantillon de transfert:\n",
      "observation.state: Type <class 'list'>, Forme (14,)\n",
      "action: Type <class 'list'>, Forme (14,)\n",
      "episode_index: 0\n",
      "frame_index: 0\n",
      "timestamp: 0.0\n",
      "next.done: False\n",
      "index: 0\n",
      "task_index: 0\n",
      "\n",
      "Exemple d'échantillon d'insertion:\n",
      "observation.state: Type <class 'list'>, Forme (14,)\n",
      "action: Type <class 'list'>, Forme (14,)\n",
      "episode_index: 0\n",
      "frame_index: 0\n",
      "timestamp: 0.0\n",
      "next.done: False\n",
      "index: 0\n",
      "task_index: 0\n",
      "\n",
      "Ajout des tags aux datasets...\n",
      "Concaténation des datasets...\n",
      "\n",
      "Dataset combiné:\n",
      "train: 45000 échantillons\n",
      "\n",
      "Répartition des tâches dans le split 'train':\n",
      "task_tag\n",
      "insertion    25000\n",
      "transfer     20000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Exemple d'échantillon du dataset combiné:\n",
      "Tâche: transfer\n",
      "episode_index: 12\n",
      "frame_index: 66\n",
      "timestamp: 1.3200000524520874\n",
      "next.done: False\n",
      "index: 4866\n",
      "task_index: 0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T22:04:49.033898Z",
     "start_time": "2025-04-17T22:04:49.024932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ActModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        obs_dim=101,       # tu devras adapter ces dimensions selon ton cas\n",
    "        action_dim=7,\n",
    "        hidden_dim=512,\n",
    "        n_layers=4,\n",
    "        dropout=0.1,\n",
    "        use_layer_norm=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.obs_dim = obs_dim\n",
    "        self.action_dim = action_dim\n",
    "\n",
    "        self.input_layer = nn.Linear(obs_dim, hidden_dim)\n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=hidden_dim,\n",
    "                nhead=8,\n",
    "                dim_feedforward=hidden_dim * 4,\n",
    "                dropout=dropout,\n",
    "                batch_first=True,\n",
    "                norm_first=use_layer_norm,\n",
    "            ) for _ in range(n_layers)\n",
    "        ])\n",
    "        self.output_layer = nn.Linear(hidden_dim, action_dim)\n",
    "\n",
    "    def forward(self, obs):\n",
    "        x = self.input_layer(obs)\n",
    "        for layer in self.transformer_layers:\n",
    "            x = layer(x)\n",
    "        return self.output_layer(x)"
   ],
   "id": "35e5e2707e336625",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T22:04:53.752097Z",
     "start_time": "2025-04-17T22:04:53.749184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from safetensors.torch import load_file\n",
    "\n",
    "def load_act_model(model_path):\n",
    "    model = ActModel(\n",
    "        obs_dim=101,       # adapte ces valeurs si nécessaire\n",
    "        action_dim=7,\n",
    "        hidden_dim=512,\n",
    "        n_layers=4,\n",
    "        dropout=0.1,\n",
    "        use_layer_norm=True\n",
    "    )\n",
    "\n",
    "    state_dict = load_file(model_path)\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    return model"
   ],
   "id": "3b0b53225b7846f8",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T22:05:37.077984Z",
     "start_time": "2025-04-17T22:05:36.947763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transfer_model = load_act_model(\"/Users/louloute/PycharmProjects/INF8225_projet/Models/transfer/model.safetensors\")\n",
    "insertion_model = load_act_model(\"/Users/louloute/PycharmProjects/INF8225_projet/Models/insertion/model.safetensors\")\n",
    "print(transfer_model)"
   ],
   "id": "895e4ce0d96d2681",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ActModel(\n",
      "  (input_layer): Linear(in_features=101, out_features=512, bias=True)\n",
      "  (transformer_layers): ModuleList(\n",
      "    (0-3): 4 x TransformerEncoderLayer(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "      (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (output_layer): Linear(in_features=512, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T22:15:19.485764Z",
     "start_time": "2025-04-17T22:07:52.492097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import des bibliothèques nécessaires\n",
    "from transformers import AutoModel, AutoConfig, PreTrainedModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import wandb  # Pour le suivi des expériences (optionnel)\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import ALOHADataset\n",
    "\n",
    "# Classe du modèle unifié\n",
    "class UnifiedALOHAModel(nn.Module):\n",
    "    def __init__(self, transfer_model, insertion_model):\n",
    "        \"\"\"\n",
    "        Crée un modèle unifié à partir des deux modèles pré-entraînés.\n",
    "        \n",
    "        Args:\n",
    "            transfer_model: Modèle pré-entraîné pour la tâche de transfert\n",
    "            insertion_model: Modèle pré-entraîné pour la tâche d'insertion\n",
    "        \"\"\"\n",
    "        super(UnifiedALOHAModel, self).__init__()\n",
    "        \n",
    "        # Sauvegarder les modèles pré-entraînés\n",
    "        self.transfer_model = transfer_model\n",
    "        self.insertion_model = insertion_model\n",
    "        \n",
    "        # Geler les paramètres des modèles pré-entraînés\n",
    "        # pour éviter de les modifier pendant l'entraînement initial\n",
    "        for param in self.transfer_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        for param in self.insertion_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Obtenir la taille de sortie des modèles\n",
    "        # À adapter selon l'architecture réelle des modèles\n",
    "        try:\n",
    "            transfer_output_size = self.transfer_model.config.hidden_size\n",
    "        except:\n",
    "            # Si le modèle n'a pas d'attribut config.hidden_size, utiliser une valeur par défaut\n",
    "            transfer_output_size = 768  # Valeur courante pour les modèles transformers\n",
    "        \n",
    "        try:\n",
    "            insertion_output_size = self.insertion_model.config.hidden_size\n",
    "        except:\n",
    "            # Si le modèle n'a pas d'attribut config.hidden_size, utiliser une valeur par défaut\n",
    "            insertion_output_size = 768  # Valeur courante pour les modèles transformers\n",
    "        \n",
    "        # Couche de sélection de tâche\n",
    "        self.task_embedding = nn.Embedding(2, 64)  # 2 tâches, embedding de dimension 64\n",
    "        \n",
    "        # Couche de fusion qui prend la sortie du modèle et l'embedding de tâche\n",
    "        self.fusion_layer = nn.Sequential(\n",
    "            nn.Linear(transfer_output_size + insertion_output_size + 64, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        \n",
    "        # Couche de sortie (à adapter selon le type de sortie attendu)\n",
    "        self.output_layer = nn.Linear(256, transfer_output_size)  # On suppose que les deux modèles ont la même dimension de sortie\n",
    "        \n",
    "        # Layer norm pour normaliser les sorties\n",
    "        self.layer_norm = nn.LayerNorm(transfer_output_size)\n",
    "    \n",
    "    def forward(self, features, task_id):\n",
    "        \"\"\"\n",
    "        Propagation avant du modèle unifié.\n",
    "        \n",
    "        Args:\n",
    "            features: Les caractéristiques d'entrée\n",
    "            task_id: L'identifiant de la tâche (0 pour transfer, 1 pour insertion)\n",
    "        \n",
    "        Returns:\n",
    "            Les prédictions du modèle\n",
    "        \"\"\"\n",
    "        # Obtenir les embeddings de la tâche\n",
    "        task_emb = self.task_embedding(task_id).squeeze(1)\n",
    "        \n",
    "        # Passer les features dans les deux modèles pré-entraînés\n",
    "        with torch.no_grad():  # Pas besoin de calculer les gradients pour les modèles gelés\n",
    "            transfer_output = self.transfer_model(features)\n",
    "            insertion_output = self.insertion_model(features)\n",
    "        \n",
    "        # Extraire les sorties des modèles (à adapter selon la structure réelle des sorties)\n",
    "        if isinstance(transfer_output, tuple):\n",
    "            transfer_output = transfer_output[0]  # Prendre le premier élément si c'est un tuple\n",
    "        \n",
    "        if isinstance(insertion_output, tuple):\n",
    "            insertion_output = insertion_output[0]  # Prendre le premier élément si c'est un tuple\n",
    "        \n",
    "        # Concaténer les sorties des deux modèles et l'embedding de tâche\n",
    "        combined = torch.cat([transfer_output, insertion_output, task_emb], dim=1)\n",
    "        \n",
    "        # Passer dans la couche de fusion\n",
    "        fused = self.fusion_layer(combined)\n",
    "        \n",
    "        # Couche de sortie\n",
    "        output = self.output_layer(fused)\n",
    "        \n",
    "        # Normaliser la sortie\n",
    "        output = self.layer_norm(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Fonction pour l'entraînement du modèle unifié\n",
    "def train_unified_model(unified_model, train_dataloader, val_dataloader, \n",
    "                        num_epochs=10, learning_rate=1e-4, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Entraîne le modèle unifié.\n",
    "    \n",
    "    Args:\n",
    "        unified_model: Le modèle unifié\n",
    "        train_dataloader: DataLoader pour les données d'entraînement\n",
    "        val_dataloader: DataLoader pour les données de validation\n",
    "        num_epochs: Nombre d'époques d'entraînement\n",
    "        learning_rate: Taux d'apprentissage\n",
    "        device: Appareil sur lequel effectuer l'entraînement ('cuda' ou 'cpu')\n",
    "    \n",
    "    Returns:\n",
    "        Le modèle entraîné et les historiques de perte\n",
    "    \"\"\"\n",
    "    # Déplacer le modèle sur l'appareil approprié\n",
    "    unified_model = unified_model.to(device)\n",
    "    \n",
    "    # Définir la fonction de perte et l'optimiseur\n",
    "    criterion = nn.MSELoss()  # À adapter selon la tâche (régression ou classification)\n",
    "    optimizer = torch.optim.Adam(unified_model.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=2, verbose=True\n",
    "    )\n",
    "    \n",
    "    # Historiques de perte\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    # Boucle d'entraînement\n",
    "    for epoch in range(num_epochs):\n",
    "        # Mode entraînement\n",
    "        unified_model.train()\n",
    "        epoch_train_loss = 0.0\n",
    "        train_batches = 0\n",
    "        \n",
    "        # Boucle sur les batches d'entraînement\n",
    "        for batch in tqdm(train_dataloader, desc=f\"Époque {epoch+1}/{num_epochs} (entraînement)\"):\n",
    "            # Déplacer les données sur l'appareil approprié\n",
    "            features = batch[\"features\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            task_id = batch[\"task_id\"].to(device)\n",
    "            \n",
    "            # Réinitialiser les gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Propagation avant\n",
    "            outputs = unified_model(features, task_id)\n",
    "            \n",
    "            # Calculer la perte\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Rétropropagation\n",
    "            loss.backward()\n",
    "            \n",
    "            # Mettre à jour les poids\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumuler la perte\n",
    "            epoch_train_loss += loss.item()\n",
    "            train_batches += 1\n",
    "        \n",
    "        # Calculer la perte moyenne pour l'époque\n",
    "        epoch_train_loss /= train_batches\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        \n",
    "        # Mode évaluation\n",
    "        unified_model.eval()\n",
    "        epoch_val_loss = 0.0\n",
    "        val_batches = 0\n",
    "        \n",
    "        # Boucle sur les batches de validation\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_dataloader, desc=f\"Époque {epoch+1}/{num_epochs} (validation)\"):\n",
    "                # Déplacer les données sur l'appareil approprié\n",
    "                features = batch[\"features\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "                task_id = batch[\"task_id\"].to(device)\n",
    "                \n",
    "                # Propagation avant\n",
    "                outputs = unified_model(features, task_id)\n",
    "                \n",
    "                # Calculer la perte\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Accumuler la perte\n",
    "                epoch_val_loss += loss.item()\n",
    "                val_batches += 1\n",
    "        \n",
    "        # Calculer la perte moyenne pour l'époque\n",
    "        epoch_val_loss /= val_batches\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        \n",
    "        # Mettre à jour le scheduler\n",
    "        scheduler.step(epoch_val_loss)\n",
    "        \n",
    "        # Afficher les pertes\n",
    "        print(f\"Époque {epoch+1}/{num_epochs} - \"\n",
    "              f\"Perte d'entraînement: {epoch_train_loss:.6f}, \"\n",
    "              f\"Perte de validation: {epoch_val_loss:.6f}\")\n",
    "    \n",
    "    return unified_model, train_losses, val_losses\n",
    "\n",
    "# Fonction pour fine-tuner le modèle unifié (dégeler certaines couches)\n",
    "def fine_tune_unified_model(unified_model, train_dataloader, val_dataloader, \n",
    "                           num_epochs=5, learning_rate=5e-5, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Fine-tune le modèle unifié en dégelant certaines couches des modèles pré-entraînés.\n",
    "    \n",
    "    Args:\n",
    "        unified_model: Le modèle unifié\n",
    "        train_dataloader: DataLoader pour les données d'entraînement\n",
    "        val_dataloader: DataLoader pour les données de validation\n",
    "        num_epochs: Nombre d'époques d'entraînement\n",
    "        learning_rate: Taux d'apprentissage\n",
    "        device: Appareil sur lequel effectuer l'entraînement ('cuda' ou 'cpu')\n",
    "    \n",
    "    Returns:\n",
    "        Le modèle fine-tuné et les historiques de perte\n",
    "    \"\"\"\n",
    "    # Dégeler les dernières couches des modèles pré-entraînés\n",
    "    for name, param in unified_model.transfer_model.named_parameters():\n",
    "        if \"layer\" in name and any(f\"layer.{i}\" in name for i in [10, 11]):  # Dégeler les 2 dernières couches\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    for name, param in unified_model.insertion_model.named_parameters():\n",
    "        if \"layer\" in name and any(f\"layer.{i}\" in name for i in [10, 11]):  # Dégeler les 2 dernières couches\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    # Entraîner le modèle avec les couches dégelées\n",
    "    return train_unified_model(unified_model, train_dataloader, val_dataloader, \n",
    "                              num_epochs=num_epochs, learning_rate=learning_rate, device=device)\n",
    "\n",
    "# Fonction principale\n",
    "def main():\n",
    "    # Charger le dataset combiné (à partir du script précédent)\n",
    "    combined_dataset = load_and_prepare_datasets()\n",
    "    \n",
    "    # Créer les datasets PyTorch\n",
    "    if \"train\" in combined_dataset and \"validation\" in combined_dataset:\n",
    "        train_dataset = ALOHADataset(combined_dataset[\"train\"])\n",
    "        val_dataset = ALOHADataset(combined_dataset[\"validation\"])\n",
    "    else:\n",
    "        # Si pas de split validation, créer un à partir du train\n",
    "        full_dataset = ALOHADataset(combined_dataset[next(iter(combined_dataset))])\n",
    "        train_size = int(0.8 * len(full_dataset))\n",
    "        val_size = len(full_dataset) - train_size\n",
    "        train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "    \n",
    "    # Créer les dataloaders\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "    \n",
    "    # Charger les modèles pré-entraînés\n",
    "    transfer_model = load_act_model(\"/Users/louloute/PycharmProjects/INF8225_projet/Models/transfer/model.safetensors\")\n",
    "    insertion_model = load_act_model(\"/Users/louloute/PycharmProjects/INF8225_projet/Models/insertion/model.safetensors\")\n",
    "    \n",
    "    # Créer le modèle unifié\n",
    "    unified_model = UnifiedALOHAModel(transfer_model, insertion_model)\n",
    "    \n",
    "    # Déterminer l'appareil à utiliser (GPU ou CPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Utilisation de l'appareil: {device}\")\n",
    "    \n",
    "    # Entraîner le modèle unifié\n",
    "    print(\"\\nEntraînement du modèle unifié...\")\n",
    "    unified_model, train_losses, val_losses = train_unified_model(\n",
    "        unified_model, train_dataloader, val_dataloader, \n",
    "        num_epochs=10, learning_rate=1e-4, device=device\n",
    "    )\n",
    "    \n",
    "    # Fine-tuner le modèle unifié\n",
    "    print(\"\\nFine-tuning du modèle unifié...\")\n",
    "    unified_model, ft_train_losses, ft_val_losses = fine_tune_unified_model(\n",
    "        unified_model, train_dataloader, val_dataloader, \n",
    "        num_epochs=5, learning_rate=5e-5, device=device\n",
    "    )\n",
    "    \n",
    "    # Tracer les courbes de perte\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Courbes de perte pour l'entraînement initial\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.title('Pertes pendant l\\'entraînement initial')\n",
    "    plt.xlabel('Époque')\n",
    "    plt.ylabel('Perte')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Courbes de perte pour le fine-tuning\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(ft_train_losses, label='Train')\n",
    "    plt.plot(ft_val_losses, label='Validation')\n",
    "    plt.title('Pertes pendant le fine-tuning')\n",
    "    plt.xlabel('Époque')\n",
    "    plt.ylabel('Perte')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_losses.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Sauvegarder le modèle unifié\n",
    "    model_save_path = \"unified_aloha_model\"\n",
    "    os.makedirs(model_save_path, exist_ok=True)\n",
    "    torch.save(unified_model.state_dict(), os.path.join(model_save_path, \"unified_model.pt\"))\n",
    "    print(f\"Modèle unifié sauvegardé dans {model_save_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "58fb220133d63b69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du dataset pour la tâche de transfert...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ab06659e44104153a5989698eeb36afe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "adc69808915e4a6b8bcd7754a738bdfe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du dataset pour la tâche d'insertion...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1fd975d805c04c2a867558e781a9f7b9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0ad4ea6c3c6486abb18380aa3ed2a93"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset transfert: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['observation.state', 'action', 'episode_index', 'frame_index', 'timestamp', 'next.done', 'index', 'task_index'],\n",
      "        num_rows: 20000\n",
      "    })\n",
      "})\n",
      "Dataset insertion: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['observation.state', 'action', 'episode_index', 'frame_index', 'timestamp', 'next.done', 'index', 'task_index'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "})\n",
      "\n",
      "Exemple d'échantillon de transfert:\n",
      "observation.state: Type <class 'list'>, Forme (14,)\n",
      "action: Type <class 'list'>, Forme (14,)\n",
      "episode_index: 0\n",
      "frame_index: 0\n",
      "timestamp: 0.0\n",
      "next.done: False\n",
      "index: 0\n",
      "task_index: 0\n",
      "\n",
      "Exemple d'échantillon d'insertion:\n",
      "observation.state: Type <class 'list'>, Forme (14,)\n",
      "action: Type <class 'list'>, Forme (14,)\n",
      "episode_index: 0\n",
      "frame_index: 0\n",
      "timestamp: 0.0\n",
      "next.done: False\n",
      "index: 0\n",
      "task_index: 0\n",
      "\n",
      "Ajout des tags aux datasets...\n",
      "Concaténation des datasets...\n",
      "\n",
      "Dataset combiné:\n",
      "train: 45000 échantillons\n",
      "Utilisation de l'appareil: cpu\n",
      "\n",
      "Entraînement du modèle unifié...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 1/10 (entraînement):   0%|          | 0/1125 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/louloute/miniconda3/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/louloute/miniconda3/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'ALOHADataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Époque 1/10 (entraînement):   0%|          | 0/1125 [07:21<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 387\u001B[0m\n\u001B[1;32m    384\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModèle unifié sauvegardé dans \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_save_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    386\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 387\u001B[0m     main()\n",
      "Cell \u001B[0;32mIn[16], line 343\u001B[0m, in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m    341\u001B[0m \u001B[38;5;66;03m# Entraîner le modèle unifié\u001B[39;00m\n\u001B[1;32m    342\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mEntraînement du modèle unifié...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 343\u001B[0m unified_model, train_losses, val_losses \u001B[38;5;241m=\u001B[39m train_unified_model(\n\u001B[1;32m    344\u001B[0m     unified_model, train_dataloader, val_dataloader, \n\u001B[1;32m    345\u001B[0m     num_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-4\u001B[39m, device\u001B[38;5;241m=\u001B[39mdevice\n\u001B[1;32m    346\u001B[0m )\n\u001B[1;32m    348\u001B[0m \u001B[38;5;66;03m# Fine-tuner le modèle unifié\u001B[39;00m\n\u001B[1;32m    349\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mFine-tuning du modèle unifié...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[16], line 214\u001B[0m, in \u001B[0;36mtrain_unified_model\u001B[0;34m(unified_model, train_dataloader, val_dataloader, num_epochs, learning_rate, device)\u001B[0m\n\u001B[1;32m    211\u001B[0m train_batches \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;66;03m# Boucle sur les batches d'entraînement\u001B[39;00m\n\u001B[0;32m--> 214\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m tqdm(train_dataloader, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mÉpoque \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_epochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (entraînement)\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    215\u001B[0m     \u001B[38;5;66;03m# Déplacer les données sur l'appareil approprié\u001B[39;00m\n\u001B[1;32m    216\u001B[0m     features \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfeatures\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m    217\u001B[0m     labels \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tqdm/std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1181\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1182\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m   1183\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[1;32m   1184\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:484\u001B[0m, in \u001B[0;36mDataLoader.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    482\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator\n\u001B[1;32m    483\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 484\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_iterator()\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:415\u001B[0m, in \u001B[0;36mDataLoader._get_iterator\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    413\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    414\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_worker_number_rationality()\n\u001B[0;32m--> 415\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _MultiProcessingDataLoaderIter(\u001B[38;5;28mself\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1138\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter.__init__\u001B[0;34m(self, loader)\u001B[0m\n\u001B[1;32m   1131\u001B[0m w\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m \u001B[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001B[39;00m\n\u001B[1;32m   1133\u001B[0m \u001B[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001B[39;00m\n\u001B[1;32m   1134\u001B[0m \u001B[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001B[39;00m\n\u001B[1;32m   1135\u001B[0m \u001B[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001B[39;00m\n\u001B[1;32m   1136\u001B[0m \u001B[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001B[39;00m\n\u001B[1;32m   1137\u001B[0m \u001B[38;5;66;03m#     AssertionError: can only join a started process.\u001B[39;00m\n\u001B[0;32m-> 1138\u001B[0m w\u001B[38;5;241m.\u001B[39mstart()\n\u001B[1;32m   1139\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues\u001B[38;5;241m.\u001B[39mappend(index_queue)\n\u001B[1;32m   1140\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers\u001B[38;5;241m.\u001B[39mappend(w)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/multiprocessing/process.py:121\u001B[0m, in \u001B[0;36mBaseProcess.start\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemon\u001B[39m\u001B[38;5;124m'\u001B[39m), \\\n\u001B[1;32m    119\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemonic processes are not allowed to have children\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    120\u001B[0m _cleanup()\n\u001B[0;32m--> 121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Popen(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sentinel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen\u001B[38;5;241m.\u001B[39msentinel\n\u001B[1;32m    123\u001B[0m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/multiprocessing/context.py:224\u001B[0m, in \u001B[0;36mProcess._Popen\u001B[0;34m(process_obj)\u001B[0m\n\u001B[1;32m    222\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m    223\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[0;32m--> 224\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _default_context\u001B[38;5;241m.\u001B[39mget_context()\u001B[38;5;241m.\u001B[39mProcess\u001B[38;5;241m.\u001B[39m_Popen(process_obj)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/multiprocessing/context.py:289\u001B[0m, in \u001B[0;36mSpawnProcess._Popen\u001B[0;34m(process_obj)\u001B[0m\n\u001B[1;32m    286\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m    287\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[1;32m    288\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpopen_spawn_posix\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[0;32m--> 289\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Popen(process_obj)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/multiprocessing/popen_spawn_posix.py:32\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, process_obj):\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fds \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 32\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(process_obj)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/multiprocessing/popen_fork.py:19\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturncode \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfinalizer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_launch(process_obj)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/multiprocessing/popen_spawn_posix.py:62\u001B[0m, in \u001B[0;36mPopen._launch\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msentinel \u001B[38;5;241m=\u001B[39m parent_r\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(parent_w, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m'\u001B[39m, closefd\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m---> 62\u001B[0m         f\u001B[38;5;241m.\u001B[39mwrite(fp\u001B[38;5;241m.\u001B[39mgetbuffer())\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     64\u001B[0m     fds_to_close \u001B[38;5;241m=\u001B[39m []\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T23:48:24.719031Z",
     "start_time": "2025-04-14T23:48:24.715837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import des bibliothèques nécessaires\n",
    "from transformers import AutoModel, AutoConfig, PreTrainedModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import wandb  # Pour le suivi des expériences (optionnel)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fonction de chargement des modèles pré-entraînés pour les deux tâches\n",
    "def load_pretrained_models():\n",
    "    \"\"\"\n",
    "    Charge les deux modèles pré-entraînés: un pour le transfert et un pour l'insertion\n",
    "    à partir des chemins locaux.\n",
    "    \"\"\"\n",
    "    print(\"Chargement du modèle pour la tâche de transfert...\")\n",
    "    transfer_model_path = \"/Users/louloute/PycharmProjects/INF8225_projet/Models/transfer/model.safetensors\"\n",
    "    transfer_model = AutoModel.from_pretrained(\n",
    "        os.path.dirname(transfer_model_path),\n",
    "        local_files_only=True\n",
    "    )\n",
    "    \n",
    "    print(\"Chargement du modèle pour la tâche d'insertion...\")\n",
    "    insertion_model_path = \"/Users/louloute/PycharmProjects/INF8225_projet/Models/insertion/model.safetensors\"\n",
    "    insertion_model = AutoModel.from_pretrained(\n",
    "        os.path.dirname(insertion_model_path),\n",
    "        local_files_only=True\n",
    "    )\n",
    "    \n",
    "    # Afficher l'architecture des modèles\n",
    "    print(\"\\nArchitecture du modèle de transfert:\")\n",
    "    print(transfer_model)\n",
    "    \n",
    "    print(\"\\nArchitecture du modèle d'insertion:\")\n",
    "    print(insertion_model)\n",
    "    \n",
    "    # Examiner les paramètres des modèles\n",
    "    transfer_params = sum(p.numel() for p in transfer_model.parameters())\n",
    "    insertion_params = sum(p.numel() for p in insertion_model.parameters())\n",
    "    \n",
    "    print(f\"\\nNombre de paramètres du modèle de transfert: {transfer_params:,}\")\n",
    "    print(f\"Nombre de paramètres du modèle d'insertion: {insertion_params:,}\")\n",
    "    \n",
    "    return transfer_model, insertion_model"
   ],
   "id": "624ffc882932aebe",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5964618e80f3f192"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
