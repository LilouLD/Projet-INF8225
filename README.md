# Installation et configuration de l‚Äôenvironnement `lerobot` avec Aloha sur Google Colab

Ce document d√©crit les √©tapes n√©cessaires pour installer l‚Äôenvironnement [`lerobot`](https://github.com/huggingface/lerobot) de Hugging Face sur Google Colab, en particulier pour utiliser les environnements de simulation Aloha. Il inclut l‚Äôinstallation des d√©pendances Python, le clonage du d√©p√¥t `lerobot`, la configuration du mode headless pour MuJoCo, ainsi que l‚Äôinstallation obligatoire du package `gym-aloha`.

Pour commencer, il faut mettre √† jour `pip` et installer les biblioth√®ques principales :

```bash
!pip install --upgrade pip
!pip install torch torchvision transformers datasets
!pip install --upgrade huggingface_hub
!pip install stable-baselines3
```

Ensuite, on clone le d√©p√¥t [`lerobot`](https://github.com/huggingface/lerobot) et on l‚Äôinstalle en mode √©ditable. Cela permet de refl√©ter toute modification locale sans avoir besoin de r√©installer √† chaque fois :

```bash
!git clone https://github.com/huggingface/lerobot.git /content/lerobot
%cd /content/lerobot
!pip install -e .
```

Il est imp√©ratif d‚Äôinstaller le package `gym-aloha` pour pouvoir charger correctement les environnements utilis√©s dans `lerobot`, m√™me si vous n‚Äôutilisez pas la simulation MuJoCo :

```bash
!pip install gym-aloha
```

Dans le cas o√π vous souhaitez utiliser l‚Äôenvironnement Aloha pour de la simulation sur Colab, par exemple pour des t√¢ches de reinforcement learning, il est n√©cessaire de configurer un environnement headless avec MuJoCo. Cela permet d‚Äôex√©cuter la simulation sans interface graphique (n√©cessaire sur Colab).

On commence par d√©marrer un serveur X virtuel via `pyvirtualdisplay` :

```python
from pyvirtualdisplay import Display

display = Display(visible=0, size=(1400, 900))
display.start()
print("‚úÖ Xvfb d√©marr√©, DISPLAY =", display.display)
```

Puis on configure les variables d‚Äôenvironnement pour forcer l‚Äôutilisation du renderer `EGL` de MuJoCo et d√©sactiver tout rendu graphique :

```python
import os

os.environ["MUJOCO_GL"] = "egl"
os.environ["DISABLE_MUJOCO_RENDERING"] = "1"
```

Il faut √©galement installer certaines biblioth√®ques syst√®me et Python :

```bash
!apt-get update -qq && apt-get install -y -qq libosmesa6-dev libglfw3 libglfw3-dev libglew-dev
!pip install -q pyvirtualdisplay glfw
```

Enfin, il faut patcher `glfw` pour √©viter toute tentative de cr√©ation de contexte graphique :

```python
import glfw

glfw.init = lambda *a, **k: True
glfw.terminate = lambda *a, **k: None
glfw.create_window = lambda *a, **k: 0
glfw.make_context_current = lambda *a, **k: None

print("‚úÖ Headless GL/MuJoCo ready (MUJOCO_GL=egl, DISABLE_MUJOCO_RENDERING=1)")
```

Une fois tout cela install√© et configur√©, vous pouvez charger les environnements Aloha, importer vos mod√®les ou datasets Hugging Face, et lancer des entra√Ænements ou des simulations de politique en reinforcement learning dans un environnement Colab parfaitement fonctionnel.



## üß† Entra√Ænement d'un mod√®le PPO sur l'environnement unifi√© Aloha

Le script fourni permet d'entra√Æner une politique unifi√©e PPO (Proximal Policy Optimization) sur les deux t√¢ches `AlohaInsertion` et `AlohaTransferCube` via l'environnement `AlohaUnifiedEnv`.

Il utilise la biblioth√®que [Stable-Baselines3](https://github.com/DLR-RM/stable-baselines3) et prend en charge :

- la parall√©lisation des environnements avec `SubprocVecEnv` (ou `DummyVecEnv` sur macOS),
- le support automatique des acc√©l√©rateurs `CUDA`, `MPS` (pour Mac), ou CPU selon l'environnement,
- la sauvegarde r√©guli√®re des checkpoints pendant l'entra√Ænement (`CheckpointCallback`),
- l'√©valuation p√©riodique avec enregistrement du meilleur mod√®le (`EvalCallback`),
- la compatibilit√© avec la nouvelle API Gymnasium (d√©finition de la seed dans `reset()`).

### üîÑ Exemple d‚Äôentra√Ænement

L‚Äôappel √† la fonction principale permet d‚Äôentra√Æner un agent avec les hyperparam√®tres suivants :

```python
model, model_path = train_unified_aloha_model(
    device="auto",           # Utilisation automatique de CUDA/MPS/CPU
    batch_size=64,
    n_steps=1024,
    total_timesteps=1_000_000,
    num_envs=4               # Parall√©lisation sur 4 environnements si disponible
)
```

Sur macOS, le script d√©tecte automatiquement le syst√®me et bascule vers `DummyVecEnv`, tout en d√©finissant les variables d‚Äôenvironnement n√©cessaires (`OBJC_DISABLE_INITIALIZE_FORK_SAFETY`) pour √©viter les erreurs li√©es au fork sur les puces Apple (M1/M2/M3).

### üìÅ Organisation des sorties

- `models/aloha_unified`: dossier de sauvegarde des mod√®les
- `logs/aloha_unified`: logs TensorBoard
- `best_model/`: mod√®le avec les meilleures performances pendant l‚Äô√©valuation
- `emergency_save/`: sauvegarde d‚Äôurgence en cas d‚Äôerreur critique
